{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1 initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/ubuntu/nbs/fish/fish_classification/data/sample/sample'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano.sandbox import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/fish/fish_classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/fish/fish_classification\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/ubuntu/nbs/fish/fish_classification/data/',\n",
       " '/home/ubuntu/nbs/fish/fish_classification/data//test/',\n",
       " '/home/ubuntu/nbs/fish/fish_classificationresults/',\n",
       " '/home/ubuntu/nbs/fish/fish_classification/data//train/',\n",
       " '/home/ubuntu/nbs/fish/fish_classification/data//models/')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /home/ubuntu/nbs/fish/fish_classification/\n",
    "import os, sys\n",
    "current_dir = os.getcwd()\n",
    "LESSON_HOME_DIR = current_dir\n",
    "DATA_HOME_DIR = current_dir\n",
    "\n",
    "DATA_HOME_DIR\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "import vgg16, utils\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from vgg16 import Vgg16\n",
    "from vgg16bn import Vgg16BN\n",
    "from utils import vgg_ft\n",
    "import glob\n",
    "import numpy as np\n",
    "from utils import save_array\n",
    "%matplotlib inline\n",
    "\n",
    "%cd $DATA_HOME_DIR\n",
    "path = DATA_HOME_DIR + '/data/'\n",
    "test_path = path + '/test/' \n",
    "results_path = DATA_HOME_DIR + 'results/'\n",
    "sample_path = path + '/sample/'\n",
    "train_path = path + '/train/'\n",
    "valid_path = path + '/valid/'\n",
    "model_path = path + '/models/'\n",
    "path, test_path, results_path, train_path, model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/fish/fish_classification/data\n"
     ]
    }
   ],
   "source": [
    "%cd $path\n",
    "%mkdir -p sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/fish/fish_classification/data\n",
      "/home/ubuntu/nbs/fish/fish_classification/data/sample\n"
     ]
    }
   ],
   "source": [
    "%cd $path\n",
    "%mkdir -p sample/train\n",
    "%mkdir -p sample/test\n",
    "%mkdir -p sample/valid\n",
    "%mkdir -p sample/results\n",
    "%mkdir -p sample/weights\n",
    "# %mkdir -p test/unknown\n",
    "\n",
    "# %mkdir -p valid/ALB  \n",
    "# %mkdir -p valid/BET  \n",
    "# %mkdir -p valid/DOL  \n",
    "# %mkdir -p valid/LAG  \n",
    "# %mkdir -p valid/NoF  \n",
    "# %mkdir -p valid/OTHER  \n",
    "# %mkdir -p valid/SHARK  \n",
    "# %mkdir -p valid/YFT\n",
    "\n",
    "%cd $sample_path \n",
    "%mkdir -p train/ALB  \n",
    "%mkdir -p train/BET  \n",
    "%mkdir -p train/DOL  \n",
    "%mkdir -p train/LAG  \n",
    "%mkdir -p train/NoF  \n",
    "%mkdir -p train/OTHER  \n",
    "%mkdir -p train/SHARK  \n",
    "%mkdir -p train/YFT\n",
    "%mkdir -p valid/ALB  \n",
    "%mkdir -p valid/BET  \n",
    "%mkdir -p valid/DOL  \n",
    "%mkdir -p valid/LAG  \n",
    "%mkdir -p valid/NoF  \n",
    "%mkdir -p valid/OTHER  \n",
    "%mkdir -p valid/SHARK  \n",
    "%mkdir -p valid/YFT\n",
    "%mkdir -p test/ALB  \n",
    "%mkdir -p test/BET  \n",
    "%mkdir -p test/DOL  \n",
    "%mkdir -p test/LAG  \n",
    "%mkdir -p test/NoF  \n",
    "%mkdir -p test/OTHER  \n",
    "%mkdir -p test/SHARK  \n",
    "%mkdir -p test/YFT\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from shutil import copyfile\n",
    "for i in ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']:\n",
    "    train_path_one_fish = train_path + \"{}\".format(i)\n",
    "    valid_path_one_fish = valid_path + \"/{}/\".format(i) \n",
    "    %cd $train_path_one_fish\n",
    "    g = glob.glob('*.jpg')\n",
    "    print len(g)/10\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(len(g)/10): \n",
    "        os.rename(shuf[i], valid_path_one_fish + shuf[i])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from shutil import copyfile\n",
    "for i in ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']:\n",
    "    train_path_one_fish = train_path + \"{}\".format(i) \n",
    "    sample_path_one_fish = sample_path + \"train/{}/\".format(i) \n",
    "    %cd $train_path_one_fish\n",
    "    g = glob.glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(len(g)/10 * 8): \n",
    "        os.rename(shuf[i], sample_path_one_fish + shuf[i])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from shutil import copyfile\n",
    "%cd $path\n",
    "for i in ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']:\n",
    "    #valid_path_one_fish = valid_path + \"/{}/\".format(i) \n",
    "    train_path_one_fish = train_path + \"{}\".format(i)\n",
    "    sample_valid_path_one_fish = sample_path + \"valid/{}/\".format(i)\n",
    "    print sample_valid_path_one_fish\n",
    "    #%cd $valid_path_one_fish\n",
    "    %cd $train_path_one_fish\n",
    "    g = glob.glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(len(g)/10): \n",
    "        os.rename(shuf[i], sample_valid_path_one_fish + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fc_model():\n",
    "    model = Sequential([\n",
    "        keras.layers.pooling.MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        keras.layers.Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        keras.layers.Dropout(0.),\n",
    "        Dense(4096, activation='relu'),\n",
    "        keras.layers.Dropout(0.),\n",
    "        Dense(8, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    for l1,l2 in zip(model.layers, fc_layers): l1.set_weights(proc_wgts(l2))\n",
    "\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def proc_wgts(layer): \n",
    "    return [o/2 for o in layer.get_weights()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2984 images belonging to 8 classes.\n",
      "Found 394 images belonging to 8 classes.\n",
      "Found 399 images belonging to 8 classes.\n",
      "Found 0 images belonging to 8 classes.\n",
      "Found 709 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# path = \"data/sample/\"\n",
    "# path = \"data/fish/\"\n",
    "batch_size=64\n",
    "\n",
    "(val_classes, trn_classes, test_classes, val_labels, trn_labels, test_labels,\n",
    "    val_filenames, filenames, test_filenames) = get_classes(sample_path)\n",
    "\n",
    "batches = get_batches(train_path, batch_size=batch_size)\n",
    "val_batches = get_batches(valid_path, batch_size=batch_size*2, shuffle=False)\n",
    "\n",
    "raw_filenames = [f.split('/')[-1] for f in filenames]\n",
    "raw_test_filenames = [f.split('/')[-1] for f in test_filenames]\n",
    "raw_val_filenames = [f.split('/')[-1] for f in val_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/fish/fish_classification/data//sample/\n"
     ]
    }
   ],
   "source": [
    "print sample_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 2 from 1 for 'MaxPool_7' (op: 'MaxPool') with input shapes: [?,1,112,128].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-48442904f183>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg_ft_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/nbs/fish/fish_classification/utils.pyc\u001b[0m in \u001b[0;36mvgg_ft_bn\u001b[0;34m(out_dim)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvgg_ft_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mvgg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVgg16BN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0mvgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/nbs/fish/fish_classification/vgg16bn.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, size, include_top)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFILE_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://files.fast.ai/models/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/nbs/fish/fish_classification/vgg16bn.pyc\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, size, include_top)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConvBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConvBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConvBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConvBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/nbs/fish/fish_classification/vgg16bn.pyc\u001b[0m in \u001b[0;36mConvBlock\u001b[0;34m(self, layers, filters)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConvolution2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/py27/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    310\u001b[0m                  output_shapes=[self.outputs[0]._keras_shape])\n\u001b[1;32m    311\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 raise Exception('All layers in a Sequential model '\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/py27/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minbound_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0;31m# this will call layer.build() if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_inbound_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minbound_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m             \u001b[0minput_added\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/py27/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36madd_inbound_node\u001b[0;34m(self, inbound_layers, node_indices, tensor_indices)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# creating the node automatically updates self.inbound_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# as well as outbound_nodes on inbound layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minbound_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_output_shape_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/py27/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36mcreate_node\u001b[0;34m(cls, outbound_layer, inbound_layers, node_indices, tensor_indices)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutbound_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_masks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0moutput_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutbound_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;31m# TODO: try to auto-infer shape if exception is raised by get_output_shape_for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/py27/lib/python2.7/site-packages/keras/layers/pooling.pyc\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    160\u001b[0m                                         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                                         \u001b[0mborder_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mborder_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                                         dim_ordering=self.dim_ordering)\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/py27/lib/python2.7/site-packages/keras/layers/pooling.pyc\u001b[0m in \u001b[0;36m_pooling_function\u001b[0;34m(self, inputs, pool_size, strides, border_mode, dim_ordering)\u001b[0m\n\u001b[1;32m    210\u001b[0m                           border_mode, dim_ordering):\n\u001b[1;32m    211\u001b[0m         output = K.pool2d(inputs, pool_size, strides,\n\u001b[0;32m--> 212\u001b[0;31m                           border_mode, dim_ordering, pool_mode='max')\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/py27/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36mpool2d\u001b[0;34m(x, pool_size, strides, border_mode, dim_ordering, pool_mode)\u001b[0m\n\u001b[1;32m   1759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1760\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'max'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1761\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1762\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'avg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1763\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.pyc\u001b[0m in \u001b[0;36mmax_pool\u001b[0;34m(value, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   1819\u001b[0m                                 \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m                                 \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1821\u001b[0;31m                                 name=name)\n\u001b[0m\u001b[1;32m   1822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.pyc\u001b[0m in \u001b[0;36m_max_pool\u001b[0;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   1636\u001b[0m   result = _op_def_lib.apply_op(\"MaxPool\", input=input, ksize=ksize,\n\u001b[1;32m   1637\u001b[0m                                 \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1638\u001b[0;31m                                 data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m   1639\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    766\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    767\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2336\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2337\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2338\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2339\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2340\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1717\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1719\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1720\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    674\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for 'MaxPool_7' (op: 'MaxPool') with input shapes: [?,1,112,128]."
     ]
    }
   ],
   "source": [
    "model = vgg_ft_bn(8)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from vgg16bn import Vgg16BN\n",
    "model = vgg_ft_bn(8)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(batches, batches.nb_sample, nb_epoch=10, validation_data=val_batches, \n",
    "                 nb_val_samples=val_batches.nb_sample, callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(conv_trn_feat, trn_labels, batch_size=batch_size, nb_epoch=2, \n",
    "             validation_data=(conv_val_feat, val_labels), callbacks=[history])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=1e-2\n",
    "model.fit(conv_trn_feat, trn_labels, batch_size=batch_size, nb_epoch=10, \n",
    "             validation_data=(conv_val_feat, val_labels), callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=5, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2984 images belonging to 8 classes.\n",
      "Found 394 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# trn = get_data(path+'sample/train')\n",
    "# val = get_data(path+'sample/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 399 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# test = get_data(path+'sample/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??image.ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save_array(path+'results/trn.dat', trn)\n",
    "# save_array(path+'results/val.dat', val)\n",
    "# save_array(path+'results/test.dat', test)\n",
    "trn = load_array(path+'results/trn.dat')\n",
    "val = load_array(path+'results/val.dat')\n",
    "test = load_array(path+'results/test.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(1e-2),\n",
    "       loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=3, \n",
    "             validation_data=(conv_val_feat, val_labels),callbacks=[history])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras import optimizers\n",
    "# sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(path+'results/ft2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_layers,fc_layers = split_at(model, Convolution2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(394, 512, 14, 14)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conv_model = Sequential(conv_layers)\n",
    "# conv_feat = conv_model.predict(trn)\n",
    "# conv_val_feat = conv_model.predict(val)\n",
    "# conv_test_feat = conv_model.predict(test)\n",
    "# save_array(path+'results/conv_val_feat.dat', conv_val_feat)\n",
    "# save_array(path+'results/conv_feat.dat', conv_feat)\n",
    "# save_array(path+'results/conv_test_feat.dat', conv_test_feat)\n",
    "conv_feat = load_array(path+'results/conv_feat.dat')\n",
    "conv_val_feat = load_array(path+'results/conv_val_feat.dat')\n",
    "conv_test_feat = load_array(path+'results/conv_test_feat.dat')\n",
    "conv_val_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bn_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "#         BatchNormalization(axis=1),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(p/2),\n",
    "#         BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(p/2),\n",
    "        BatchNormalization(),\n",
    "        Dense(8, activation='softmax')\n",
    "    ]\n",
    "p=1\n",
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# bn_model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=5, \n",
    "#              validation_data=(conv_val_feat, val_labels),callbacks=[history])\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=5, \n",
    "             validation_data=(conv_val_feat, val_labels),callbacks=[history])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"556pt\" viewBox=\"0.00 0.00 282.00 556.00\" width=\"282pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 552)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-552 278,-552 278,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140695358911184 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140695358911184</title>\n",
       "<polygon fill=\"none\" points=\"0,-511.5 0,-547.5 274,-547.5 274,-511.5 0,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"137\" y=\"-525.8\">maxpooling2d_input_3 (InputLayer)</text>\n",
       "</g>\n",
       "<!-- 140695358906192 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140695358906192</title>\n",
       "<polygon fill=\"none\" points=\"6,-438.5 6,-474.5 268,-474.5 268,-438.5 6,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"137\" y=\"-452.8\">maxpooling2d_13 (MaxPooling2D)</text>\n",
       "</g>\n",
       "<!-- 140695358911184&#45;&gt;140695358906192 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140695358911184-&gt;140695358906192</title>\n",
       "<path d=\"M137,-511.313C137,-503.289 137,-493.547 137,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"140.5,-484.529 137,-474.529 133.5,-484.529 140.5,-484.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140695358906128 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140695358906128</title>\n",
       "<polygon fill=\"none\" points=\"64,-365.5 64,-401.5 210,-401.5 210,-365.5 64,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"137\" y=\"-379.8\">flatten_5 (Flatten)</text>\n",
       "</g>\n",
       "<!-- 140695358906192&#45;&gt;140695358906128 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140695358906192-&gt;140695358906128</title>\n",
       "<path d=\"M137,-438.313C137,-430.289 137,-420.547 137,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"140.5,-411.529 137,-401.529 133.5,-411.529 140.5,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140695358906320 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140695358906320</title>\n",
       "<polygon fill=\"none\" points=\"65.5,-292.5 65.5,-328.5 208.5,-328.5 208.5,-292.5 65.5,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"137\" y=\"-306.8\">dense_15 (Dense)</text>\n",
       "</g>\n",
       "<!-- 140695358906128&#45;&gt;140695358906320 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140695358906128-&gt;140695358906320</title>\n",
       "<path d=\"M137,-365.313C137,-357.289 137,-347.547 137,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"140.5,-338.529 137,-328.529 133.5,-338.529 140.5,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140695358910608 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140695358910608</title>\n",
       "<polygon fill=\"none\" points=\"55.5,-219.5 55.5,-255.5 218.5,-255.5 218.5,-219.5 55.5,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"137\" y=\"-233.8\">dropout_9 (Dropout)</text>\n",
       "</g>\n",
       "<!-- 140695358906320&#45;&gt;140695358910608 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140695358906320-&gt;140695358910608</title>\n",
       "<path d=\"M137,-292.313C137,-284.289 137,-274.547 137,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"140.5,-265.529 137,-255.529 133.5,-265.529 140.5,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140695358910672 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140695358910672</title>\n",
       "<polygon fill=\"none\" points=\"65.5,-146.5 65.5,-182.5 208.5,-182.5 208.5,-146.5 65.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"137\" y=\"-160.8\">dense_16 (Dense)</text>\n",
       "</g>\n",
       "<!-- 140695358910608&#45;&gt;140695358910672 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140695358910608-&gt;140695358910672</title>\n",
       "<path d=\"M137,-219.313C137,-211.289 137,-201.547 137,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"140.5,-192.529 137,-182.529 133.5,-192.529 140.5,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140695358910800 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140695358910800</title>\n",
       "<polygon fill=\"none\" points=\"51,-73.5 51,-109.5 223,-109.5 223,-73.5 51,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"137\" y=\"-87.8\">dropout_10 (Dropout)</text>\n",
       "</g>\n",
       "<!-- 140695358910672&#45;&gt;140695358910800 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140695358910672-&gt;140695358910800</title>\n",
       "<path d=\"M137,-146.313C137,-138.289 137,-128.547 137,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"140.5,-119.529 137,-109.529 133.5,-119.529 140.5,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140695358910864 -->\n",
       "<g class=\"node\" id=\"node8\"><title>140695358910864</title>\n",
       "<polygon fill=\"none\" points=\"65.5,-0.5 65.5,-36.5 208.5,-36.5 208.5,-0.5 65.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"137\" y=\"-14.8\">dense_17 (Dense)</text>\n",
       "</g>\n",
       "<!-- 140695358910800&#45;&gt;140695358910864 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>140695358910800-&gt;140695358910864</title>\n",
       "<path d=\"M137,-73.3129C137,-65.2895 137,-55.5475 137,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"140.5,-46.5288 137,-36.5288 133.5,-46.5289 140.5,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "SVG(model_to_dot(bn_model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from IPython.display import Image, display, SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "# Show the model in ipython notebook\n",
    "figure = SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n",
    "display(figure)\n",
    "\n",
    "# Save the model as png file\n",
    "from keras.utils.visualize_util import plot\n",
    "plot(model, to_file='model_final.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proc_wgts(layer): return [o/2 for o in layer.get_weights()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fc_model():\n",
    "    model = Sequential([\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(8, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    for l1,l2 in zip(model.layers, fc_layers): l1.set_weights(proc_wgts(l2))\n",
    "    model.compile(Adam(lr=0.01),loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# bn_model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=3, \n",
    "#              validation_data=(conv_val_feat, val_labels))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import History \n",
    "history = History()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_acc=[]\n",
    "val_class_acc=[]\n",
    "class_loss=[]\n",
    "val_class_loss=[]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "history_list = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_acc_percent = []\n",
    "for i in class_acc:\n",
    "    i = i * 100\n",
    "    class_acc_percent.append(i)\n",
    "    \n",
    "val_class_acc_percent = []\n",
    "for i in val_class_acc:\n",
    "    i = i * 100\n",
    "    val_class_acc_percent.append(i)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "fc_model = get_fc_model()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "bn_model.optimizer.lr = 0.01\n",
    "bn_model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=1, \n",
    "             validation_data=(conv_val_feat, val_labels), callbacks=[history])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "history_list = history.history\n",
    "class_acc += history_list['acc']\n",
    "val_class_acc += history_list['val_acc']\n",
    "class_loss += history_list['loss']\n",
    "val_class_loss += history_list['val_loss']\n",
    "print len(class_acc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bn_model.evaluate(conv_test_feat, test_labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trn = get_data(path+'sample/train', (360,640))\n",
    "val = get_data(path+'sample/valid', (360,640))\n",
    "test = get_data(path+'sample/test', (360,640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(path+'results/trn_640.dat', trn)\n",
    "save_array(path+'results/val_640.dat', val)\n",
    "save_array(path+'results/test_640.dat', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn = load_array(path+'results/trn_640.dat')\n",
    "val = load_array(path+'results/val_640.dat')\n",
    "test = load_array(path+'results/test_640.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vgg640 = Vgg16BN((360, 640)).model\n",
    "vgg640.pop()\n",
    "vgg640.input_shape, vgg640.output_shape\n",
    "vgg640.compile(Adam(), 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# conv_val_feat = vgg640.predict(val, batch_size=32, verbose=1)\n",
    "# conv_trn_feat = vgg640.predict(trn, batch_size=32, verbose=1)\n",
    "# save_array(path+'results/conv_val_640.dat', conv_val_feat)\n",
    "# save_array(path+'results/conv_trn_640.dat', conv_trn_feat)\n",
    "# conv_test_feat = vgg640.predict(test, batch_size=32, verbose=1)\n",
    "# save_array(path+'results/conv_test_640.dat', conv_test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_val_feat = load_array(path+'results/conv_val_640.dat')\n",
    "conv_trn_feat = load_array(path+'results/conv_trn_640.dat')\n",
    "conv_test_feat = load_array(path+'results/conv_test_640.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d_bn(x, nb_filter, nb_row, nb_col, subsample=(1, 1)):\n",
    "    x = Convolution2D(nb_filter, nb_row, nb_col,\n",
    "                      subsample=subsample, activation='relu', border_mode='same')(x)\n",
    "    return BatchNormalization(axis=1)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def incep_block(x):\n",
    "    branch1x1 = conv2d_bn(x, 32, 1, 1, subsample=(2, 2))\n",
    "    branch5x5 = conv2d_bn(x, 24, 1, 1)\n",
    "    branch5x5 = conv2d_bn(branch5x5, 32, 5, 5, subsample=(2, 2))\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 32, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 48, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 48, 3, 3, subsample=(2, 2))\n",
    "\n",
    "    branch_pool = AveragePooling2D(\n",
    "        (3, 3), strides=(2, 2), border_mode='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 16, 1, 1)\n",
    "    return merge([branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "              mode='concat', concat_axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input(vgg640.layers[-1].output_shape[1:]) \n",
    "# x = BatchNormalization(axis=1)(inp)\n",
    "# x = incep_block(x)\n",
    "# x = incep_block(x)\n",
    "# x = incep_block(x)\n",
    "# x = Dropout(0.75)(x)\n",
    "# x = Convolution2D(8,3,3, border_mode='same')(x)\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# outp = Activation('softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrg_model = Model([inp], outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrg_model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lrg_model.fit(conv_trn_feat, trn_labels, batch_size=batch_size, nb_epoch=10, \n",
    "             validation_data=(conv_val_feat, val_labels), callbacks=[history])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lrg_model.optimizer.lr = 0.00001\n",
    "lrg_model.fit(conv_trn_feat, trn_labels, batch_size=batch_size, nb_epoch=15, \n",
    "             validation_data=(conv_val_feat, val_labels), callbacks=[history])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "history_list = history.history\n",
    "class_acc += history_list['acc']\n",
    "val_class_acc += history_list['val_acc']\n",
    "class_loss += history_list['loss']\n",
    "val_class_loss += history_list['val_loss']\n",
    "print len(class_acc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lrg_model.evaluate(conv_val_feat, val_labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(class_acc_percent)\n",
    "plt.plot(val_class_acc_percent)\n",
    "plt.title('Google Net accuracy')\n",
    "plt.ylabel('accuracy(%)')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.yticks(np.arange(0, 104, 4))\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(class_loss)\n",
    "plt.plot(val_class_loss)\n",
    "plt.title('Google Net loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.yticks(np.arange(0, 8, 0.3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(class_acc_percent)\n",
    "plt.plot(val_class_acc_percent)\n",
    "plt.title('improved model accuracy')\n",
    "plt.ylabel('accuracy(%)')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.yticks(np.arange(40, 103, 3))\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(class_loss)\n",
    "plt.plot(val_class_loss)\n",
    "plt.title('improved model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.yticks(np.arange(0, 8, 0.3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(path+'models/conv_512_6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.evaluate(conv_val_feat, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_layers,_ = split_at(vgg640, Convolution2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nf=128; p=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lrg_layers():\n",
    "    return [\n",
    "        BatchNormalization(axis=1, input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D((1,2)),\n",
    "        Convolution2D(8,3,3, border_mode='same'),\n",
    "        Dropout(p),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Activation('softmax')\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th\n"
     ]
    }
   ],
   "source": [
    "lrg_model = Sequential(get_lrg_layers())\n",
    "lrg_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "lrg_model.fit(conv_trn_feat, trn_labels, batch_size=batch_size, nb_epoch=2, \n",
    "             validation_data=(conv_val_feat, val_labels), callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrg_model.optimizer.lr=1e-2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lrg_model.fit(conv_trn_feat, trn_labels, batch_size=batch_size, nb_epoch=10, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "history_list = history.history\n",
    "class_acc += history_list['acc']\n",
    "val_class_acc += history_list['val_acc']\n",
    "class_loss += history_list['loss']\n",
    "val_class_loss += history_list['val_loss']\n",
    "print len(class_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrg_model.optimizer.lr=1e-3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lrg_model.fit(conv_trn_feat, trn_labels, batch_size=batch_size, nb_epoch=10, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "history_list = history.history\n",
    "class_acc += history_list['acc']\n",
    "val_class_acc += history_list['val_acc']\n",
    "class_loss += history_list['loss']\n",
    "val_class_loss += history_list['val_loss']\n",
    "print len(class_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nf=128; p=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lrg_layers():\n",
    "    return [\n",
    "        BatchNormalization(axis=1, input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D((1,2)),\n",
    "        Convolution2D(8,3,3, border_mode='same'),\n",
    "        Dropout(p),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Activation('softmax')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th\n"
     ]
    }
   ],
   "source": [
    "lrg_model = Sequential(get_lrg_layers())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "inp = Input(conv_layers[-1].output_shape[1:])\n",
    "# x = MaxPooling2D()(inp)\n",
    "x = BatchNormalization(axis=1, input_shape=(512,14,14))(inp)\n",
    "# x = Flatten()(x)\n",
    "# x = Dense(512, activation='relu')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Dropout(p)(x)\n",
    "# x = Dense(512, activation='relu')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Dropout(p/2)(x)\n",
    "x = Convolution2D(128,3,3, activation='relu', border_mode='same')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Convolution2D(128,3,3, activation='relu', border_mode='same')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Convolution2D(128,3,3, activation='relu', border_mode='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(p/2)(x)\n",
    "x_bb = Dense(4, name='bb')(x)\n",
    "x_class = Dense(8, activation='softmax', name='class')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-18d9042f4f78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mborder_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mborder_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inp' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "x = BatchNormalization(axis=1, input_shape=(512,14,14))(inp)\n",
    "x = Convolution2D(128,3,3, activation='relu', border_mode='same')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = Convolution2D(128,3,3, activation='relu', border_mode='same')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = Convolution2D(128,3,3, activation='relu', border_mode='same')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x_b = Convolution2D(4,3,3, border_mode='same')(x)\n",
    "x_bb = GlobalAveragePooling2D(name='bb')(x_b)\n",
    "x_c = Convolution2D(8,3,3, border_mode='same')(x)\n",
    "x_c = GlobalAveragePooling2D()(x_c)\n",
    "x_class = Activation('softmax', name = 'class')(x_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model([inp], [x_bb, x_class])\n",
    "model.compile(Adam(lr=0.01), loss=['mse', 'categorical_crossentropy'], metrics=['accuracy'],\n",
    "             loss_weights=[.001, 1.])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from IPython.display import Image, display, SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "# Show the model in ipython notebook\n",
    "figure = SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n",
    "display(figure)\n",
    "\n",
    "# Save the model as png file\n",
    "from keras.utils.visualize_util import plot\n",
    "# plot(model, to_file='model_final.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_acc=[]\n",
    "val_class_acc=[]\n",
    "class_loss=[]\n",
    "val_class_loss=[]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.optimizer.lr = 1e-2\n",
    "\n",
    "model.fit(conv_trn_feat, [trn_bbox, trn_labels], batch_size=batch_size, nb_epoch=10, \n",
    "             validation_data=(conv_val_feat, [val_bbox, val_labels]), callbacks=[history])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print history_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "history_list = history.history\n",
    "class_acc += history_list['class_acc']\n",
    "val_class_acc += history_list['val_class_acc']\n",
    "class_loss += history_list['class_loss']\n",
    "val_class_loss += history_list['val_class_loss']\n",
    "print len(class_acc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.optimizer.lr = 1e-3\n",
    "\n",
    "model.fit(conv_trn_feat, [trn_bbox, trn_labels], batch_size=batch_size, nb_epoch=10, \n",
    "             validation_data=(conv_val_feat, [val_bbox, val_labels]), callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "history_list = history.history\n",
    "class_acc += history_list['class_acc']\n",
    "val_class_acc += history_list['val_class_acc']\n",
    "class_loss += history_list['class_loss']\n",
    "val_class_loss += history_list['val_class_loss']\n",
    "print len(class_acc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.optimizer.lr = 1e-4\n",
    "\n",
    "model.fit(conv_trn_feat, [trn_bbox, trn_labels], batch_size=batch_size, nb_epoch=10, \n",
    "             validation_data=(conv_val_feat, [val_bbox, val_labels]), callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "history_list = history.history\n",
    "class_acc += history_list['class_acc']\n",
    "val_class_acc += history_list['val_class_acc']\n",
    "class_loss += history_list['class_loss']\n",
    "val_class_loss += history_list['val_class_loss']\n",
    "print len(class_acc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit(conv_trn_feat, [trn_bbox, trn_labels], batch_size=batch_size, nb_epoch=5, \n",
    "             validation_data=(conv_val_feat, [val_bbox, val_labels]), callbacks=[history])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "history_list = history.history\n",
    "class_acc += history_list['class_acc']\n",
    "val_class_acc += history_list['val_class_acc']\n",
    "class_loss += history_list['class_loss']\n",
    "val_class_loss += history_list['val_class_loss']\n",
    "print len(class_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "class_acc = class_acc[0:9]\n",
    "val_class_acc = val_class_acc[0:9]\n",
    "class_loss = class_loss[0:9]\n",
    "val_class_loss = val_class_loss[0:9]\n",
    "print len(class_acc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "model.optimizer.lr = 0.01\n",
    "\n",
    "model.fit(conv_feat, [trn_bbox, trn_labels], batch_size=batch_size, nb_epoch=5, \n",
    "             validation_data=(conv_val_feat, [val_bbox, val_labels]), callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "history_list = history.history\n",
    "class_acc += history_list['class_acc']\n",
    "val_class_acc += history_list['val_class_acc']\n",
    "class_loss += history_list['class_loss']\n",
    "val_class_loss += history_list['val_class_loss']\n",
    "print len(class_acc)\n",
    "# print class_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import History \n",
    "history = History()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.evaluate(conv_test_feat, [test_bbox, test_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(path+'models/bn_anno02.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gen = image.ImageDataGenerator(horizontal_flip=True)\n",
    "\n",
    "# gen = image.ImageDataGenerator(rotation_range=90, horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "# gen = image.ImageDataGenerator(rotation_range=10, width_shift_range=0.1, width_zoom_range=0.2, height_shift_range=0.1, shear_range=0.15, zoom_range=0.1, channel_shift_range=10., horizontal_flip=True)\n",
    "\n",
    "# gen = image.ImageDataGenerator(rotation_range=10, width_shift_range=0.05,width_zoom_range=0.05, height_shift_range=0.05, shear_range=0.05, zoom_range=0.05, channel_shift_range=10, horizontal_flip=True)\n",
    "\n",
    "# gen = image.ImageDataGenerator(rotation_range=15, width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.1, horizontal_flip=True)\n",
    "batch_size = 64\n",
    "batches = get_batches(train_path, gen, batch_size=batch_size)\n",
    "# NB: We don't want to augment or shuffle the validation set\n",
    "val_batches = get_batches(valid_path, shuffle=False, batch_size=batch_size)\n",
    "test_batches = get_batches(test_path, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "opt = RMSprop(lr=0.00001, rho=0.7)\n",
    "model = vgg_ft(8)\n",
    "layers = model.layers\n",
    "last_conv_idx = [index for index,layer in enumerate(layers) if type(layer) is keras.layers.convolutional.Convolution2D][-1]\n",
    "# fc_layers = layers[last_conv_idx+1:]\n",
    "conv_layers = layers[:last_conv_idx+1]\n",
    "conv_model = Sequential(conv_layers)\n",
    "# fc_model = get_fc_model()\n",
    "for layer in conv_model.layers: layer.trainable = False\n",
    "# Look how easy it is to connect two models together!\n",
    "# conv_model.add(fc_model)\n",
    "conv_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conv_model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=3, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model.save_weights(model_path + 'aug4.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conv_model.load_weights(model_path + 'final1.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conv_layers[-1].output_shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p=0.6\n",
    "def get_bn_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(p),\n",
    "        BatchNormalization(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(p),\n",
    "        BatchNormalization(),\n",
    "        Dense(8, activation='softmax')\n",
    "        ]\n",
    "bn_model = Sequential(get_bn_layers(0.6))\n",
    "bn_layers = get_bn_layers(0.6)\n",
    "bn_layers.pop()\n",
    "bn_layers.append(Dense(8,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model = Sequential(conv_layers)\n",
    "for layer in final_model.layers: layer.trainable = False\n",
    "for layer in bn_layers: final_model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for l1,l2 in zip(bn_model.layers, bn_layers):\n",
    "    l2.set_weights(l1.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model.compile(optimizer=Adam(), \n",
    "                    loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "final_model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=10, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "final_model.optimizer.lr.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model.save_weights(model_path + 'final1.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "bn_model.load_weights(model_path + 'final1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model.optimizer.lr = 0.001"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_batches = get_batches(test_path, shuffle=False, batch_size=batch_size, class_mode=None)\n",
    "preds = bn_model.predict_generator(test_batches, test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "preds = preds.clip(min=0.05, max=0.95)\n",
    "print preds[:5]\n",
    "filenames = test_batches.filenames\n",
    "ids = np.array([(f[f.find('/')+1:]) for f in filenames])\n",
    "ids.resize((1000, 1))\n",
    "subm = np.hstack((ids,preds))\n",
    "print subm[:5]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "submission_file_name = 'submission_aug03.csv'\n",
    "print subm[:5]\n",
    "np.savetxt(submission_file_name, subm, fmt='%s,%s,%s,%s,%s,%s,%s,%s,%s', header='image,ALB,BET,DOL,LAG,NoF,OTHER,SHARK,YFT', comments='')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from IPython.display import FileLink\n",
    "%cd $LESSON_HOME_DIR\n",
    "FileLink('/home/ubuntu/nbs/fish/fish_classification/'+submission_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 373 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# gen = image.ImageDataGenerator(horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "# gen = image.ImageDataGenerator(rotation_range=10, width_shift_range=0.1, width_zoom_range=0.2, height_shift_range=0.1, shear_range=0.15, zoom_range=0.1, channel_shift_range=10., horizontal_flip=True)\n",
    "\n",
    "# gen = image.ImageDataGenerator(rotation_range=10, width_shift_range=0.05,width_zoom_range=0.05, height_shift_range=0.05, shear_range=0.05, zoom_range=0.05, channel_shift_range=10, horizontal_flip=True)\n",
    "\n",
    "# gen = image.ImageDataGenerator(rotation_range=15, width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.1, horizontal_flip=True)\n",
    "# gen = image.ImageDataGenerator(rotation_range=8, width_shift_range=0.08, height_shift_range=0.08, zoom_range=0.08, shear_range=0.3)\n",
    "\n",
    "batch_size = 64\n",
    "# NB: We don't want to augment or shuffle the validation set\n",
    "val_batches = get_batches(valid_path, shuffle=False, batch_size=batch_size)\n",
    "test_batches = get_batches(test_path, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "# from keras import backend as K\n",
    "# from keras.optimizers import SGD\n",
    "\n",
    "def get_bn_layers(conv_layers, p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(p),\n",
    "        BatchNormalization(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(p),\n",
    "        BatchNormalization(),\n",
    "        Dense(8, activation='softmax')\n",
    "            ]\n",
    "\n",
    "def get_model():\n",
    "    model = vgg_ft(8)\n",
    "    layers = model.layers\n",
    "    last_conv_idx = [index for index,layer in enumerate(layers) if type(layer) is keras.layers.convolutional.Convolution2D][-1]\n",
    "    conv_layers = layers[:last_conv_idx+1]\n",
    "    final_model = Sequential(conv_layers)\n",
    "    drop_out_rate=0.5\n",
    "    bn_model = Sequential(get_bn_layers(conv_layers, drop_out_rate))\n",
    "    bn_layers = get_bn_layers(conv_layers, drop_out_rate)\n",
    "    bn_layers.pop()\n",
    "    bn_layers.append(Dense(8,activation='softmax'))\n",
    "    for layer in final_model.layers: \n",
    "        layer.trainable = False\n",
    "    for layer in bn_layers: \n",
    "        final_model.add(layer)\n",
    "    for l1,l2 in zip(bn_model.layers, bn_layers):\n",
    "        l2.set_weights(l1.get_weights())\n",
    "    final_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model():\n",
    "    model = get_model()\n",
    "#     model.optimizer.lr=0.001\n",
    "#     model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=1, \n",
    "#                         validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "    \n",
    "#     model.optimizer.lr=0.1\n",
    "#     model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=4, \n",
    "#                         validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "#     print ('0.1 learning rate ------------done----------')\n",
    "#     model.optimizer.lr=0.01\n",
    "#     model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=4, \n",
    "#                         validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "#     print ('0.01 learning rate ------------done----------')\n",
    "#     model.optimizer.lr=0.001\n",
    "#     model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=4, \n",
    "#                         validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "#     print ('0.001 learning rate ------------done----------')\n",
    "#     model.optimizer.lr=0.0001\n",
    "#     model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=4, \n",
    "#                         validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "#     print ('0.0001 learning rate ------------done----------')\n",
    "#     model.optimizer.lr=0.00001\n",
    "#     model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=4, \n",
    "#                         validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "#     print ('0.00001 learning rate ------------done----------')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models.save_weights(path + 'sample_vertical_and_horizontal_flip03.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "models = fit_model() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "loop = 1\n",
    "for i in range(loop):\n",
    "    gen = image.ImageDataGenerator()\n",
    "    print (i, 'no')\n",
    "    batches = get_batches(train_path, gen, batch_size=batch_size)\n",
    "    models = fit_model()\n",
    "loop = 1\n",
    "for i in range(loop):\n",
    "    gen = image.ImageDataGenerator(shear_range=0.05)\n",
    "    print (i, 'shear_range=0.05')\n",
    "    batches = get_batches(train_path, gen, batch_size=batch_size)\n",
    "    models = fit_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3777 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = image.ImageDataGenerator(channel_shift_range=10)\n",
    "batches = get_batches(train_path, gen, batch_size=batch_size)\n",
    "model_01 = fit_model()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data= get_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model_01.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_01.save_weights(path + 'vgg_shear0.05_dropout0.5_model02_subset01.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gen = image.ImageDataGenerator(shear_range=0.05)\n",
    "batches = get_batches(train_path, gen, batch_size=batch_size)\n",
    "model_01 = fit_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_01.save_weights(path + 'vgg_shear0.05_dropout0.5_model03_subset01.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gen = image.ImageDataGenerator()\n",
    "gen_train = image.ImageDataGenerator()\n",
    "batches = get_batches(train_path, gen, batch_size=batch_size)\n",
    "model_01 = fit_model()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_data = get_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model_01.predict(test_data, batch_size = batch_size * 2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "test_batches = gen.flow(test_data, preds, batch_size = 16)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "val_batches = get_batches(valid_path, batch_size = 4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_batches = get_batches(train_path, gen_train, batch_size = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3404"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batches.N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??MixIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mi = MixIterator([train_batches, test_batches, val_batches])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_01.save_weights(path + 'vgg_shear0.05_dropout0.5_model02_subset02.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_01.load_weights(path + 'vgg_shear0.05_dropout0.5_model01_subset01.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_01.load_weights(path + 'vgg_mnist_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_01.load_weights(path + 'vgg_mnist_0_sub10.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "val_batches.nb_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 373 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "val_data = get_data(valid_path)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_01.optimizer.lr=0.00001\n",
    "model_01.fit_generator(mi, mi.N, nb_epoch=8, validation_data=(val_data, val_labels))\n",
    "\n",
    "# model_01.optimizer.lr=0.000005\n",
    "# model_01.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=10, \n",
    "#                         validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "model_01.optimizer.lr=0.00001\n",
    "model_01.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=5, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "\n",
    "# model_01.optimizer.lr=0.000005\n",
    "# model_01.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=10, \n",
    "#                         validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_01.load_weights(path + 'trainset_01shear0.05_02no_aug_dropout0.5_model_mnist_0_sub02.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_01.optimizer.lr=0.00001\n",
    "model_01.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=10, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "\n",
    "# model_01.optimizer.lr=0.000005\n",
    "# model_01.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=10, \n",
    "#                         validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "\n",
    "model_01.save_weights(path + 'trainset_01shear0.05_02no_aug_dropout0.5_model_mnist_0_sub04.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_01.load_weights(path + 'trainset_01shear0.05_02no_aug_dropout0.5_model_mnist_0_sub03.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_01.load_weights(path + 'vgg_mnist_1.h5')\n",
    "model_01.optimizer.lr=0.00001\n",
    "model_01.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=10, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "model_01.optimizer.lr=0.000005\n",
    "model_01.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=10, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "model_01.save_weights(path + 'vgg_mnist_1_sub02.h5')\n",
    "\n",
    "\n",
    "\n",
    "model_01.load_weights(path + 'vgg_mnist_1.h5')\n",
    "model_01.optimizer.lr=0.00001\n",
    "model_01.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=10, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "model_01.optimizer.lr=0.000005\n",
    "model_01.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=10, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "model_01.save_weights(path + 'vgg_mnist_1_sub02.h5')\n",
    "\n",
    "model_01.load_weights(path + 'vgg_mnist_2.h5')\n",
    "model_01.optimizer.lr=0.00001\n",
    "model_01.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=10, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "model_01.optimizer.lr=0.000005\n",
    "model_01.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=10, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "model_01.save_weights(path + 'vgg_mnist_2_sub02.h5')\n",
    "\n",
    "model_01.load_weights(path + 'vgg_mnist_3.h5')\n",
    "model_01.optimizer.lr=0.00001\n",
    "model_01.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=10, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "model_01.optimizer.lr=0.000005\n",
    "model_01.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=10, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "model_01.save_weights(path + 'vgg_mnist_3_sub02.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gen = image.ImageDataGenerator(shear_range=0.05, channel_shift_range=10)\n",
    "batches = get_batches(train_path, gen, batch_size=batch_size)\n",
    "model_01 = fit_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_01.save_weights(path + 'vgg_shear0.05_dropout0.5_model_test01_subset02.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,m in enumerate(models):\n",
    "    m.save_weights(path + 'vgg_mnist_'  + str(i) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,m in enumerate(models):\n",
    "    m.save_weights(path + 'vgg_mnist_' + str(i) + '.pkl')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "preds = model_01.predict_generator(test_batches, test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "all_preds = np.stack([m.predict_generator(test_batches, test_batches.nb_sample) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = all_preds.mean(axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "preds = preds.clip(min=0.05, max=0.95)\n",
    "print preds[:5]\n",
    "filenames = test_batches.filenames\n",
    "ids = np.array([(f[f.find('/')+1:]) for f in filenames])\n",
    "ids.resize((1000, 1))\n",
    "subm = np.hstack((ids,preds))\n",
    "print subm[:5]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%cd $path\n",
    "submission_file_name = 'trainset_01shear0.05_02no_aug_dropout0.5_model_01_sub04.csv'\n",
    "print subm[:5]\n",
    "np.savetxt(submission_file_name, subm, fmt='%s,%s,%s,%s,%s,%s,%s,%s,%s', header='image,ALB,BET,DOL,LAG,NoF,OTHER,SHARK,YFT', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rotation_range=10, width_shift_range=0.1, \n",
    "       height_shift_range=0.1, width_zoom_range=0.2, shear_range=0.15, zoom_range=0.1, \n",
    "       channel_shift_range=10., horizontal_flip=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3777 images belonging to 8 classes.\n",
      "Found 722 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = image.ImageDataGenerator(rotation_range=15, width_shift_range=0.1, \n",
    "                               height_shift_range=0.1, zoom_range=0.1, horizontal_flip=True)\n",
    "\n",
    "batch_size=64\n",
    "batches = get_batches(train_path, gen, batch_size=batch_size)\n",
    "# batches = get_batches(train_path, batch_size=batch_size)\n",
    "# NB: We don't want to augment or shuffle the validation set\n",
    "val_batches = get_batches(valid_path, shuffle=False, batch_size=batch_size)\n",
    "test_batches = get_batches(test_path, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "current_dir = os.getcwd()\n",
    "LESSON_HOME_DIR = current_dir\n",
    "DATA_HOME_DIR = current_dir\n",
    "print DATA_HOME_DIR\n",
    "gen = image.ImageDataGenerator(rotation_range=180, horizontal_flip=True, vertical_flip=True )\n",
    "# Create a 'batch' of a single image\n",
    "img = np.expand_dims(ndimage.imread('/home/ubuntu/nbs/fish/fish_classification/data/train/SHARK/img_00247.jpg'),0)\n",
    "# Request the generator to create batches from this image\n",
    "aug_iter = gen.flow(img)\n",
    "# Get eight examples of these augmented images\n",
    "aug_imgs = [next(aug_iter)[0].astype(np.uint8) for i in range(8)]\n",
    "# The original\n",
    "plt.imshow(img[0])\n",
    "# Augmented data\n",
    "plots(aug_imgs, (40,30), 8)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from utils import get_batches, onehot\n",
    "\n",
    "val_classes = val_batches.classes\n",
    "trn_classes = batches.classes\n",
    "val_labels = onehot(val_classes)\n",
    "trn_labels = onehot(trn_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??gen.get_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()\n",
    "model=vgg.model\n",
    "last_conv_idx = [i for i,l in enumerate(model.layers) if type(l) is Convolution2D][-1]\n",
    "conv_layers = model.layers[:last_conv_idx+1]\n",
    "conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_features = conv_model.predict_generator(val_batches, val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_features_01 = conv_model.predict_generator(batches, batches.nb_sample*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??conv_model.predict_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_features = conv_model.predict_generator(test_batches, test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trn_features.shape\n",
    "print val_features.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "(val_classes, trn_classes, val_labels, trn_labels, \n",
    "    val_filenames, filenames, test_filenames) = get_classes(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??get_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??get_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_labels = np.vstack((trn_labels,trn_labels, trn_labels, trn_labels, trn_labels))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from utils import get_batches, onehot\n",
    "val_classes = val_batches.classes\n",
    "trn_classes = batches.classes \n",
    "val_labels = onehot(val_classes)\n",
    "trn_labels = onehot(trn_classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(model_path + 'da_train_convlayer_features.bc', trn_features)\n",
    "save_array(model_path + 'valid_convlayer_features.bc', val_features)\n",
    "save_array(model_path + 'test_convlayer_features.bc', test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(model_path + 'da_train_convlayer_features_01.bc', trn_features_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18885, 512, 14, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_features = load_array(model_path + 'da_train_convlayer_features_01.bc')\n",
    "val_features = load_array(model_path + 'valid_convlayer_features.bc')\n",
    "test_features = load_array(model_path + 'test_convlayer_features.bc')\n",
    "trn_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = bn_model.predict(test_features, batch_size=batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bn_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dropout(p/2),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p/2),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(8, activation='softmax')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print trn_features.shape, trn_labels.shape\n",
    "print val_features.shape, val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.fit(trn_features, trn_labels, batch_size=batch_size, nb_epoch=4, \n",
    "             validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "bn_model.optimizer.lr=0.0001\n",
    "bn_model.fit(trn_features, trn_labels, batch_size=batch_size, nb_epoch=2, \n",
    "             validation_data=(val_features, val_labels))\n",
    "bn_model.optimizer.lr=0.00001\n",
    "bn_model.fit(trn_features, trn_labels, batch_size=batch_size, nb_epoch=2, \n",
    "             validation_data=(val_features, val_labels))\n",
    "bn_model.optimizer.lr=0.00001\n",
    "bn_model.fit(trn_features, trn_labels, batch_size=batch_size, nb_epoch=2, \n",
    "             validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.load_weights(model_path+'latest_weights_no_aug.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(model_path+'latest_weights_aug01.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.load_weights(model_path+'latest_weights_aug01.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Copy the weights from the pre-trained model.\n",
    "# NB: Since we're removing dropout, we want to half the weights\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fc_model = get_fc_model()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "fc_model.fit(trn_features, trn_labels, nb_epoch=8, \n",
    "             batch_size=batch_size, validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??fc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model.save_weights(model_path+'no_dropout01.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# dim_ordering='tf' uses tensorflow dimension ordering,\n",
    "#   which is the same order as matplotlib uses for display.\n",
    "# Therefore when just using for display purposes, this is more convenient\n",
    "gen = image.ImageDataGenerator(rotation_range=10, width_shift_range=0.1, \n",
    "       height_shift_range=0.1, width_zoom_range=0.2, shear_range=0.15, zoom_range=0.1, \n",
    "       channel_shift_range=10., horizontal_flip=True, dim_ordering='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "no_of_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `ImageDataGenerator` not found.\n"
     ]
    }
   ],
   "source": [
    "??ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3404 images belonging to 8 classes.\n",
      "Found 373 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = image.ImageDataGenerator(rotation_range=15, width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.1, horizontal_flip=True)\n",
    "batches = vgg.get_batches(train_path, gen, batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(valid_path, batch_size=batch_size*2)\n",
    "vgg.finetune(batches)\n",
    "vgg.model.optimizer.lr = 0.01   # ?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# latest_weights_filename = None\n",
    "for epoch in range(no_of_epochs):\n",
    "    print \"Running epoch: %d\" % epoch\n",
    "    vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "    latest_weights_filename = 'ft%d.h5' % epoch\n",
    "    vgg.model.save_weights(results_path+latest_weights_filename)\n",
    "print \"Completed %s fit operations\" % no_of_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4 generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??vgg.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = vgg.model\n",
    "layers = model.layers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vgg.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??vgg.finetune"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from keras import backend as K\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "opt = RMSprop(lr=0.1)\n",
    "batches = vgg.get_batches(train_path, batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(valid_path, batch_size=batch_size*2)\n",
    "for layer in layers[12:]: layer.trainable=True\n",
    "for epoch in range(12, 20):\n",
    "    K.set_value(opt.lr, 0.001)\n",
    "    vgg.model.load_weights('/home/ubuntu/nbs/fish/fish_classification/data/results/ft10.h5')\n",
    "    vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "    latest_weights_filename = 'ft11.h5'\n",
    "    vgg.model.save_weights(results_path+latest_weights_filename)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "print test_path\n",
    "vgg.model.load_weights('/home/ubuntu/nbs/fish/fish_classification/data/results/ft10.h5')\n",
    "batches, preds = vgg.test('/home/ubuntu/nbs/fish/fish_classification/data/test/', batch_size = batch_size*2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "print test_path\n",
    "vgg.model.load_weights('/home/ubuntu/nbs/fish/fish_classification/data/models/no_dropout01.h5')\n",
    "batches, preds = vgg.test('/home/ubuntu/nbs/fish/fish_classification/data/test/', batch_size = batch_size*2)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "preds = preds.clip(min=0.05, max=0.95)\n",
    "print preds[:5]\n",
    "filenames = batches.filenames\n",
    "filenames = batches.filenames\n",
    "ids = np.array([(f[f.find('/')+1:]) for f in filenames])\n",
    "ids.resize((1000, 1))\n",
    "subm = np.hstack((ids,preds))\n",
    "print subm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `vgg.model.save_array` not found.\n"
     ]
    }
   ],
   "source": [
    "?vgg.model.save_array"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "save_array(results_path + 'test_preds.dat', preds)\n",
    "save_array(results_path + 'ids.dat', ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5 validate the preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expected_labels = val_batches.classes #0 or 1\n",
    "\n",
    "#Round our predictions to 0/1 to generate labels\n",
    "our_predictions = preds[:]\n",
    "our_labels = np.round(1-our_predictions)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(expected_labels, our_labels)\n",
    "plot_confusion_matrix(cm, val_batches.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6 submit"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "preds = load_array(results_path + 'test_preds.dat')\n",
    "filenames = load_array(results_path + 'ids.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Raw Predictions: \" + str(preds[:5])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "submission_file_name = 'submission_aug01.csv'\n",
    "print subm[:5]\n",
    "np.savetxt(submission_file_name, subm, fmt='%s,%s,%s,%s,%s,%s,%s,%s,%s', header='image,ALB,BET,DOL,LAG,NoF,OTHER,SHARK,YFT', comments='')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from IPython.display import FileLink\n",
    "%cd $LESSON_HOME_DIR\n",
    "FileLink('/home/ubuntu/nbs/fish/fish_classification/'+submission_file_name)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
